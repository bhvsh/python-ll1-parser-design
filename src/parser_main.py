import parser_engine

sample_input_string = ""

rules=["S -> A B",
       "A -> t m()",
       "B -> b M W r ( id ) d",
       "M -> t id ; | #",
       "E1 -> e a e o e ; | #",
       "E2 -> id a e ; | #",
       "W -> do E1 E2 w ( e ) | #"]

nonterm_userdef=['S','A','B','M','E1','E2','W']
term_userdef=['t','m()','b','d','r','e','o',';','id','a','do','w','(',')']

sample_input_string=str_to_load

#Sending output to parser from a file (generated by lexer)
#inps = ''
#with open('tokens.txt', 'r+') as f:
#    for line in f.readlines():
#        inps += line
#sample_input_string = inps

diction = {}
firsts = {}
follows = {}

computeAllFirsts()

start_symbol = list(diction.keys())[0]

computeAllFollows()

(parsing_table, result, tabTerm) = createParseTable()

if sample_input_string != None:
    validity = validateStringUsingStackBuffer(parsing_table, result,
                                              tabTerm, sample_input_string,
                                              term_userdef, start_symbol)
    print(validity)

else:
    print("\nNo input string detected")